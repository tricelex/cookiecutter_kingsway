version: '3.8'

x-common-spec:
  &common-spec
  env_file: ./config/.env

x-django-container-spec:
  &django-container-spec
  <<: *common-spec
  build:
    context: .
    dockerfile: Dockerfile-django
    args:
      DJANGO_ENV: development
      DPT_VENV_CACHING: $DPT_VENV_CACHING
    cache_from:
      - "{{ cookiecutter.project_slug }}:dev"
      - "{{ cookiecutter.project_slug }}:latest"
      - "*"
  volumes:
    - &py-code-volume ".:/code"
    - ".data/media:/files/media"
    - &poetry-volume "${DPT_POETRY_CACHE_DIR:-.data/pycache/pypoetry}:/root/.cache/pypoetry"
    - &pip-volume "${DPT_PIP_CACHE_DIR:-.data/pycache/pip}:/root/.cache/pip"
    - &pyproject-volume "./pyproject.toml:/pyproject.toml"
    - &poetrylock-volume "./poetry.lock:/poetry.lock"
  depends_on:
    - postgres
    - rabbitmq
    - mailhog
  environment:
    PYTHONUNBUFFERED: "0"

x-celery-environment:
  &celery-environment
  environment:
    PYTHONUNBUFFERED: "0"
    SKIP_INSTALL: "1"

services:
  postgres:
    <<: *common-spec
    image: postgres:14.1
    restart: unless-stopped
    volumes:
      - ".data/postgres:/var/lib/postgresql/data"
      - ".data/db-mirror:/db-mirror" # Used by ansible mirror playbook
      - "./scripts/create-citext-extension.sql:/docker-entrypoint-initdb.d/create-citext-extension.sql"
    # Comment in the following lines to connect to your Dockerized instance of Postgres from your host machine.
    # Change the host port (before colon) if you have a local instance of Postgres running on that port.
    ports:
      - "5432:5432"
    environment:
      # credentials taken from .env file
      POSTGRES_USER: "${DJANGO_DATABASE_USER:-{{ cookiecutter.project_slug }}}"
      POSTGRES_PASSWORD: "${DJANGO_DATABASE_PASSWORD:-{{ cookiecutter.project_slug }}}"

  rabbitmq:
    <<: *common-spec
    image: rabbitmq:3.7.2-management-alpine
    hostname: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_ERLANG_COOKIE=JKSDFHSJF7834GHBF3FBEI
      - RABBITMQ_DEFAULT_USER=rabbitmq
      - RABBITMQ_DEFAULT_PASS=rabbitmq
      - RABBITMQ_DEFAULT_VHOST=my_vhost

  django:
    <<: *django-container-spec
    image: "{{ cookiecutter.project_slug }}:dev"
    ports:
      - "8000:8000"
    volumes:
      - *py-code-volume
    depends_on:
      - postgres
      - rabbitmq
    command: >
      bash -c "python manage.py migrate && python manage.py runserver 0.0.0.0:8000"
    entrypoint: /usr/bin/wait-for-it.sh postgres:5432 -t 60 -- entrypoint.sh --

  celery:
    <<: *django-container-spec
    <<: *celery-environment
    restart: unless-stopped
    entrypoint: /usr/bin/wait-for-it.sh postgres:5432 -t 60 -- entrypoint.sh --
    # command: celery --app {{ cookiecutter.project_slug }}.tasks.celery worker --autoscale 6,2 --loglevel INFO
    # Use in debug mode for watching
    command: watchfiles celery.__main__.main --args '-A {{ cookiecutter.project_slug }}.tasks.celery worker -l INFO'

  celery_beat:
    <<: *django-container-spec
    <<: *celery-environment
    container_name: lalala_celery_beat
    volumes:
      - ".data/celery:/celery"
      - *py-code-volume
      - *poetry-volume
      - *pip-volume
      - *pyproject-volume
      - *poetrylock-volume
    depends_on:
      - postgres
      - rabbitmq
      - django
    entrypoint: entrypoint.sh --
    # Disable pidfile by specifying an empty one. We used fixed container_name which provides single-running-process
    #  guarantee and the lack of pidfile ensures that Celery Beat starts even if the Docker container was killed and
    #  then restarted (in which case the pidfile would still be present).
    command: celery --app {{ cookiecutter.project_slug }}.tasks.celery beat --loglevel INFO --pidfile= --schedule /celery/celerybeat-schedule

  flower:
    <<: *django-container-spec
    <<: *celery-environment
    container_name: {{ cookiecutter.project_slug }}_flower
    volumes:
      - ".data/celery:/celery"
      - *py-code-volume
      - *poetry-volume
      - *pip-volume
      - *pyproject-volume
      - *poetrylock-volume
    depends_on:
      - celery_beat
    command: celery --app {{ cookiecutter.project_slug }}.tasks.celery  -b "${CELERY_BROKER_URL}" flower --loglevel INFO --basic_auth="${CELERY_FLOWER_USER}:${CELERY_FLOWER_PASSWORD}"
    ports:
      - "5555:5555"
    environment:
      - CELERY_FLOWER_USER=flower
      - CELERY_FLOWER_PASSWORD=flower

  mailhog:
    <<: *common-spec
    image: mailhog/mailhog:v1.0.0
    container_name: {{ cookiecutter.project_slug }}_mailhog
    ports:
      - "8025:8025"
    logging:
      driver: "none"
